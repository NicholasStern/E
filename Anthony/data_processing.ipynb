{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "In this notebook we do all of the necessary data processing for the Meme Generator data that we scraped. In the original [Dank Learning](https://arxiv.org/pdf/1806.04510.pdf) paper that we follow throughout our project, their vocabulary size is roughly 40,000. With any filtering we do, we seek to keep our vocabulary size to a maximum of 40,000 to be in line with them and because we are concerned with model training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/anthonyrentsch/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import pickle\n",
    "from pickle_utils import pickle_load, pickle_dump\n",
    "from loadGlove import loadGloveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155392, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54053</th>\n",
       "      <td>My Precious Gollum</td>\n",
       "      <td>Hello TARA...</td>\n",
       "      <td>HELLO PRECIOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67160</th>\n",
       "      <td>Ecstatic Michael Phelps</td>\n",
       "      <td>tHERE'S A POT OF THE STUFF?</td>\n",
       "      <td>i LOVE POT.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49626</th>\n",
       "      <td>katt williams shocked</td>\n",
       "      <td>What</td>\n",
       "      <td>you actually thought you were getting rp?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>Okay Guy</td>\n",
       "      <td>TOOK AN ARROW TO THE KNEE</td>\n",
       "      <td>OKAY..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22047</th>\n",
       "      <td>Rich Men Laughing</td>\n",
       "      <td>and then we told them</td>\n",
       "      <td>their health insurance premiums wouldnt go up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150193</th>\n",
       "      <td>kim jong un</td>\n",
       "      <td>they see me rulin'</td>\n",
       "      <td>they hatin'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121915</th>\n",
       "      <td>The Olympic Queen</td>\n",
       "      <td>vodka</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132328</th>\n",
       "      <td>Paperclip</td>\n",
       "      <td>it looks like you're having trouble</td>\n",
       "      <td>fapping to this meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120444</th>\n",
       "      <td>Honey BooBoo</td>\n",
       "      <td>happy birthday</td>\n",
       "      <td>ali boo boo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15655</th>\n",
       "      <td>Not sure if troll</td>\n",
       "      <td>not sure if nicki minaj</td>\n",
       "      <td>or a mutant from mortal combat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image                           above_text  \\\n",
       "54053        My Precious Gollum                        Hello TARA...   \n",
       "67160   Ecstatic Michael Phelps          tHERE'S A POT OF THE STUFF?   \n",
       "49626     katt williams shocked                                 What   \n",
       "9727                   Okay Guy            TOOK AN ARROW TO THE KNEE   \n",
       "22047         Rich Men Laughing                and then we told them   \n",
       "150193              kim jong un                   they see me rulin'   \n",
       "121915        The Olympic Queen                                vodka   \n",
       "132328                Paperclip  it looks like you're having trouble   \n",
       "120444             Honey BooBoo                       happy birthday   \n",
       "15655         Not sure if troll              not sure if nicki minaj   \n",
       "\n",
       "                                           below_text  \n",
       "54053                                  HELLO PRECIOUS  \n",
       "67160                                     i LOVE POT.  \n",
       "49626       you actually thought you were getting rp?  \n",
       "9727                                           OKAY..  \n",
       "22047   their health insurance premiums wouldnt go up  \n",
       "150193                                    they hatin'  \n",
       "121915                                            NaN  \n",
       "132328                           fapping to this meme  \n",
       "120444                                    ali boo boo  \n",
       "15655                  or a mutant from mortal combat  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = pd.read_csv(\"captions.csv\", error_bad_lines=False, warn_bad_lines=False)\n",
    "print(captions.shape)\n",
    "captions.sample(10, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our captions are split up into two pieces: the `above_text`, the piece of the meme caption that is located above the base image, and the `below_text`, the piece of the caption that is located below the base image. This follows from a recommendation in the original Dank Learning paper that we follow to predict both parts of the caption rather than the full concatenated caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create small subsample\n",
    "# num_labels = 100\n",
    "# random_labels = list(np.random.choice(captions.image.unique(), num_labels))\n",
    "# captions = captions[captions['image'].isin(random_labels)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load GloVe and save objects for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_objs = loadGloveModel(\"glove.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_index_dict = glove_objs[0]\n",
    "glove_embedding_weights = glove_objs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1917494, (1917494, 300))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_index_dict), glove_embedding_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_dump(glove_objs, \"glove_objs.pkl\")\n",
    "# glove_objs = pickle_load(\"glove_objs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean captions and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Remove rows when there are NaNs in the captions or labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image           13\n",
       "above_text    6137\n",
       "below_text    7199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pd.isna(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18546</th>\n",
       "      <td>NaN</td>\n",
       "      <td>several people get up and leave as they can se...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43899</th>\n",
       "      <td>NaN</td>\n",
       "      <td>teacher is even later than you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57525</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ekki málið :)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100719</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ert þú starfsmaður þarna eða eigandi?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100723</th>\n",
       "      <td>NaN</td>\n",
       "      <td>uppiskorpi!!!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100725</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Eða bara eldisfiskur. LOL.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100728</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Takk kærlega fyrir þetta :)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>makes us strong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>makes us strong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114690</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Nei þá nærðu í rauðvín</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114721</th>\n",
       "      <td>NaN</td>\n",
       "      <td>merkileg blanda alveg;)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115828</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Fannst þetta bara krúttleg mynd =)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I NEVER ASK FOR THIS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image                                         above_text below_text\n",
       "18546    NaN  several people get up and leave as they can se...        NaN\n",
       "43899    NaN                     teacher is even later than you        NaN\n",
       "57525    NaN                                      Ekki málið :)        NaN\n",
       "100719   NaN              Ert þú starfsmaður þarna eða eigandi?        NaN\n",
       "100723   NaN                                      uppiskorpi!!!        NaN\n",
       "100725   NaN                         Eða bara eldisfiskur. LOL.        NaN\n",
       "100728   NaN                        Takk kærlega fyrir þetta :)        NaN\n",
       "105241   NaN                                    makes us strong        NaN\n",
       "105243   NaN                                    makes us strong        NaN\n",
       "114690   NaN                             Nei þá nærðu í rauðvín        NaN\n",
       "114721   NaN                            merkileg blanda alveg;)        NaN\n",
       "115828   NaN                 Fannst þetta bara krúttleg mynd =)        NaN\n",
       "132127   NaN                               I NEVER ASK FOR THIS        NaN"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.iloc[np.where(pd.isna(captions.image))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = captions[pd.notnull(captions.image)]\n",
    "captions = captions.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image         0\n",
       "above_text    0\n",
       "below_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pd.isna(captions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Convert all captions and labels to lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions['image'] = captions['image'].str.lower()\n",
    "captions['above_text'] = captions['above_text'].str.lower()\n",
    "captions['below_text'] = captions['below_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148743</th>\n",
       "      <td>bender popular</td>\n",
       "      <td>todos se iban a paro</td>\n",
       "      <td>la usm solo quería ser popular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60086</th>\n",
       "      <td>uncle dolan pls</td>\n",
       "      <td>clovhy pls</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81607</th>\n",
       "      <td>lawn chair blown over</td>\n",
       "      <td>cerberus earthquake 2012</td>\n",
       "      <td>we will rebuild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79323</th>\n",
       "      <td>pizzeria los hijos de puta</td>\n",
       "      <td>y monsters university?</td>\n",
       "      <td>para cuando monsters university?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42541</th>\n",
       "      <td>liberal douche garofalo</td>\n",
       "      <td>overregulates everything into complete disfunc...</td>\n",
       "      <td>defends it as \"the new normal\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>joker mind loss</td>\n",
       "      <td>a girl kiss a girl in public and no one bats a...</td>\n",
       "      <td>a boy kiss a boy in public and everyone loses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152361</th>\n",
       "      <td>over obsessive girlfriend</td>\n",
       "      <td>why</td>\n",
       "      <td>is sleep more important than me kim?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142516</th>\n",
       "      <td>tony horton</td>\n",
       "      <td>recovery week</td>\n",
       "      <td>it's a beautiful thing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42871</th>\n",
       "      <td>mens wearhouse</td>\n",
       "      <td>you're gonna like how the site looks</td>\n",
       "      <td>i guarantee it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7923</th>\n",
       "      <td>butthurt dweller</td>\n",
       "      <td>talk shit on internet</td>\n",
       "      <td>feel superior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image  \\\n",
       "148743              bender popular   \n",
       "60086              uncle dolan pls   \n",
       "81607        lawn chair blown over   \n",
       "79323   pizzeria los hijos de puta   \n",
       "42541      liberal douche garofalo   \n",
       "6074               joker mind loss   \n",
       "152361   over obsessive girlfriend   \n",
       "142516                 tony horton   \n",
       "42871               mens wearhouse   \n",
       "7923              butthurt dweller   \n",
       "\n",
       "                                               above_text  \\\n",
       "148743                               todos se iban a paro   \n",
       "60086                                          clovhy pls   \n",
       "81607                            cerberus earthquake 2012   \n",
       "79323                              y monsters university?   \n",
       "42541   overregulates everything into complete disfunc...   \n",
       "6074    a girl kiss a girl in public and no one bats a...   \n",
       "152361                                                why   \n",
       "142516                                      recovery week   \n",
       "42871                you're gonna like how the site looks   \n",
       "7923                                talk shit on internet   \n",
       "\n",
       "                                               below_text  \n",
       "148743                     la usm solo quería ser popular  \n",
       "60086                                                      \n",
       "81607                                     we will rebuild  \n",
       "79323                   para cuando monsters university?!  \n",
       "42541                      defends it as \"the new normal\"  \n",
       "6074    a boy kiss a boy in public and everyone loses ...  \n",
       "152361               is sleep more important than me kim?  \n",
       "142516                            it's a beautiful thing!  \n",
       "42871                                      i guarantee it  \n",
       "7923                                        feel superior  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.sample(10, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Remove rows with non-English or offensive words\n",
    "\n",
    "We noticed that many captions were in other languages, particularly Spanish and Russian. We wish to get rid of these in our final dataset, so we filter out all captions with words that do not appear in the words in GloVe (which are all English words). This is a rather harsh criteria and we do remove some captions with English words that simply do not show up in GloVe.\n",
    "\n",
    "Instead we opt to filter out as much offensive content as we can. We noticed that many of the memes from Meme Generator contained hateful content and we would not like to perpetuate this type of content in our project. Further, the authors of Dank Learning recommended addressing this issue in future work.\n",
    "\n",
    "We filter out words in our training set that contain any words from a [list](https://gist.github.com/jamiew/1112488) of \"bad words\" compiled as a part of Google's \"What Do You Love\" project. The idea to filter out words from this list comes from a [paper](https://www.usenix.org/system/files/conference/foci17/foci17-paper-nithyanand.pdf) which attempted to measure offensive speech in political discourse on Reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-English words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_words = set(list(glove_index_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72453 observations deleted because they contain non-English words.\n"
     ]
    }
   ],
   "source": [
    "nonenglishinds = []\n",
    "i = 0\n",
    "for ind, cap in enumerate(captions.above_text + \" \" + captions.below_text):\n",
    "    for word in cap.split():\n",
    "        if word not in glove_words:\n",
    "            nonenglishinds.append(ind)\n",
    "\n",
    "nonenglishinds = list(set(nonenglishinds))           \n",
    "print(\"{} observations deleted because they contain non-English words.\".format(len(nonenglishinds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = captions.drop(captions.index[nonenglishinds]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Offensive words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'}'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badwords = []\n",
    "i = 1\n",
    "google_wdyl_path = \"google_twunter_lol.txt\"\n",
    "with open(google_wdyl_path, 'r') as f:\n",
    "    for line in f:\n",
    "        for word in line.split(\":\"):\n",
    "            if i % 2 == 0:\n",
    "                badwords.append(word.replace('\"', \"\"))\n",
    "            i += 1\n",
    "badwords.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10641 observations deleted because they contain bad words.\n"
     ]
    }
   ],
   "source": [
    "badwordinds = []\n",
    "i = 0\n",
    "for ind, cap in enumerate(captions.above_text + \" \" + captions.below_text):\n",
    "    for word in cap.split():\n",
    "        if word in badwords:\n",
    "            badwordinds.append(ind)\n",
    "print(\"{} observations deleted because they contain bad words.\".format(len(badwordinds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = captions.drop(captions.index[badwordinds]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Remove other bad rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine `above_text` and `below_text` here with appropriate breakpoint tokens. Will re-use this later to tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint_captions = \"<sos> \" + captions.above_text + \" <break> \" + captions.below_text + \" <eos>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit to caption length to under some reasonable upper bound for a meme caption. For many, the scrape just got messed up and appended many captions into one observation. We simply discard these rows, which are a small subset of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 3525 rows\n"
     ]
    }
   ],
   "source": [
    "longinds = []\n",
    "maxcaplen = 20\n",
    "howmany = 0\n",
    "for i, cap in enumerate(breakpoint_captions):\n",
    "    splitcap = cap.split()\n",
    "    if len(splitcap) > maxcaplen:\n",
    "        longinds.append(i)\n",
    "        howmany += 1\n",
    "captions = captions.drop(captions.index[longinds]).reset_index(drop=True)\n",
    "breakpoint_captions = breakpoint_captions.drop(breakpoint_captions.index[longinds])\n",
    "print(\"Deleted {} rows for being too long.\".format(howmany))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Clean miscellaneous bad labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions['image'] = captions['image'].str.replace(\"third\",'3rd ')\n",
    "captions['image'] = captions['image'].str.replace(\"3rd -world\",'3rd world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After all of this cleaning we are left with 70122 observations.\n"
     ]
    }
   ],
   "source": [
    "print(\"After all of this cleaning we are left with {} observations.\".format(captions.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create word mappings\n",
    "\n",
    "Structure borrowed from Harvard IACS 2019 ComputeFest [code](https://github.com/Harvard-IACS/2019-computefest/blob/master/Friday/data_preprocess.ipnb.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(lst):\n",
    "    vocabcount = Counter(w for txt in lst for w in txt.split())\n",
    "    vocab = map(lambda x: x[0], sorted(vocabcount.items(), key=lambda x: -x[1]))\n",
    "    return list(vocab), vocabcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocabcount = get_vocab(list(captions.image) + list(captions.above_text) + list(captions.below_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 36706\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. word2idx and idx2word mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = 1\n",
    "eos = 0  \n",
    "br = 2\n",
    "start_idx = br+1 \n",
    "\n",
    "word2idx = {word: idx+start_idx for idx, word in enumerate(vocab)}\n",
    "word2idx['<sos>'] = sos\n",
    "word2idx['<eos>'] = eos\n",
    "word2idx['<break>'] = br\n",
    "\n",
    "idx2word = {ix: word for word, ix in word2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Form embedding matrix\n",
    "\n",
    "For the words in our observed data, grab the GloVe embeddings. If the word didn't exist in GloVe, initialize it with uniform weights. This should not be the case since we filter out words that don't exist in GloVe, but we do this to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "embedding_dim = 300\n",
    "shape = (vocab_size, embedding_dim)\n",
    "scale = glove_embedding_weights.std()*np.sqrt(12)/2 \n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)\n",
    "\n",
    "c = 0\n",
    "for i in range(vocab_size):\n",
    "    w = idx2word[i]\n",
    "    g = glove_index_dict.get(w, glove_index_dict.get(w))\n",
    "    if g is None and w.startswith('#'):\n",
    "        w = w[1:]\n",
    "        g = glove_index_dict.get(w, glove_index_dict.get(w))\n",
    "    if g is not None:\n",
    "        embedding[i,:] = glove_embedding_weights[g,:]\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Create final data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next cells create what should be the data we need. This includes right padding tokenzied captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add padding\n",
    "def rpad(x, maxlen=maxcaplen, eos=eos):\n",
    "    assert maxlen >= 0\n",
    "    if maxlen == 0:\n",
    "        return [eos]\n",
    "    n = len(x)\n",
    "    if n > maxlen:\n",
    "        x = x[-maxlen:]\n",
    "        n = maxlen\n",
    "    return x + [eos]*(maxlen-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_captions = [rpad([word2idx[token] for token in cap.split()]) for cap in breakpoint_captions]                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_images = [[word2idx[token] for token in cap.split()] for cap in captions.image]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE LABEL:  y u no\n",
      "TOKENIZED IMAGE LABEL:  [92, 72, 21]\n",
      "CAPTION:  justin bieber y u no dead\n",
      "CAPTION WITH BREAKPOINTS:  <sos> justin bieber <break> y u no dead <eos>\n",
      "TOKENIZED CAPTION:  [1, 304, 446, 2, 92, 72, 21, 176, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CAPTION LENGTH:  20\n",
      "<sos>\n",
      "justin\n",
      "bieber\n",
      "<break>\n",
      "y\n",
      "u\n",
      "no\n",
      "dead\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "print(\"IMAGE LABEL: \", captions.image[24])\n",
    "print(\"TOKENIZED IMAGE LABEL: \", tokenized_images[24])\n",
    "print(\"CAPTION: \", captions.above_text[24] + \" \" + captions.below_text[24])\n",
    "print(\"CAPTION WITH BREAKPOINTS: \", breakpoint_captions[24])\n",
    "print(\"TOKENIZED CAPTION: \", tokenized_captions[24])\n",
    "print(\"CAPTION LENGTH: \", len(tokenized_captions[24]))\n",
    "for token in tokenized_captions[24]:\n",
    "    print(idx2word[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Validate findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 20, index: 67 \n",
      " <sos> memegenerator <break> y u no let me see what memes i have created and what memes i like <eos>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxlen = 0\n",
    "longcap = \"\"\n",
    "ind = 0\n",
    "lens = []\n",
    "for i, cap in enumerate(breakpoint_captions):\n",
    "    splitcap = cap.split()\n",
    "    lens.append(len(splitcap))\n",
    "    if len(splitcap) > maxlen:\n",
    "        maxlen = len(splitcap)\n",
    "        longcap = cap\n",
    "        ind = i\n",
    "print(\"Length: {}, index: {} \\n {}\".format(maxlen, ind, longcap))\n",
    "plt.hist(lens)\n",
    "plt.xlim([0, 30])\n",
    "plt.title(\"Distribution of caption lengths\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_copy = captions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_junk(x):\n",
    "    illegal = [\"?\", \"'\", \" /\", \"[\", \"]\", \".\", \"á\", \" -\", \"*\", \"/\", \"!\", \n",
    "               \"ñ\", \"í\", \"(\", \")\", \"$\", \"\\\"\", \"`\", \":\", \";\"]\n",
    "    end_illegal = [' ', '-']\n",
    "    impute_chars = ['- ',' ', '_']\n",
    "    \n",
    "    for char in end_illegal:\n",
    "        while x[-1] == char:  # strip off illegal end characters\n",
    "            x = x[:-1]\n",
    "        \n",
    "    \n",
    "    for char in illegal:\n",
    "        if char in x:  # strip off overall illegal characters\n",
    "            x = x.replace(char, \"\")\n",
    "        \n",
    "    for char in impute_chars: # impute certain characters\n",
    "        x = x.replace(char, \"-\")\n",
    "    return x + \".jpg\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill out csv\n",
    "captions_copy['file_path'] = captions_copy['image'].apply(strip_junk)\n",
    "captions_copy['full_caption'] = breakpoint_captions\n",
    "captions_copy['full_padded_caption'] = pd.Series((cap for cap in tokenized_captions))\n",
    "captions_copy['tokenized_label'] = tokenized_images\n",
    "captions_copy['image'] = captions_copy['image'].apply(lambda x: x.strip(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=103456513...\n",
      "writing bytes [0, 103456513)... done.\n"
     ]
    }
   ],
   "source": [
    "out_file = \"full_clean_processed_data.pkl\"\n",
    "out_objs = (embedding, idx2word, word2idx, captions_copy)\n",
    "pickle_dump(out_objs, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "      <th>file_path</th>\n",
       "      <th>full_caption</th>\n",
       "      <th>full_padded_caption</th>\n",
       "      <th>tokenized_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36402</th>\n",
       "      <td>overly-excited oprah!!!</td>\n",
       "      <td>change your birthday</td>\n",
       "      <td>you get cake and you get cake and you get cake</td>\n",
       "      <td>overly-excited-oprah.jpg</td>\n",
       "      <td>&lt;sos&gt; uses pit flies under map &lt;break&gt; says he...</td>\n",
       "      <td>[1, 603, 17, 105, 2, 5, 47, 1210, 10, 5, 47, 1...</td>\n",
       "      <td>[2825, 2826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64258</th>\n",
       "      <td>finnishproblems</td>\n",
       "      <td>works</td>\n",
       "      <td>like a train toilet</td>\n",
       "      <td>finnishproblems.jpg</td>\n",
       "      <td>&lt;sos&gt; hates old people drivers &lt;break&gt; is old ...</td>\n",
       "      <td>[1, 1740, 2, 41, 6, 1940, 894, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61411</th>\n",
       "      <td>neo matrix</td>\n",
       "      <td>what if i told you</td>\n",
       "      <td>i am actually morpheus</td>\n",
       "      <td>neo-matrix.jpg</td>\n",
       "      <td>&lt;sos&gt; christmas is a cooked goose &lt;break&gt; so p...</td>\n",
       "      <td>[1, 33, 20, 3, 71, 5, 2, 3, 142, 458, 574, 0, ...</td>\n",
       "      <td>[938, 334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62462</th>\n",
       "      <td>caixas ss3</td>\n",
       "      <td>what</td>\n",
       "      <td></td>\n",
       "      <td>caixas-ss3.jpg</td>\n",
       "      <td>&lt;sos&gt; who can fix it &lt;break&gt; not us of course ...</td>\n",
       "      <td>[1, 33, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1233, 1220]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33392</th>\n",
       "      <td>dumb blonde</td>\n",
       "      <td>someone called me a blonde</td>\n",
       "      <td>but i have black hair</td>\n",
       "      <td>dumb-blonde.jpg</td>\n",
       "      <td>&lt;sos&gt;  &lt;break&gt; praise the lawd for vtec &lt;eos&gt;</td>\n",
       "      <td>[1, 237, 501, 15, 6, 875, 2, 52, 3, 19, 55, 65...</td>\n",
       "      <td>[402, 875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40523</th>\n",
       "      <td>gaaay</td>\n",
       "      <td>so hardcoore</td>\n",
       "      <td></td>\n",
       "      <td>gaaay.jpg</td>\n",
       "      <td>&lt;sos&gt; gooood &lt;break&gt; now give it to me &lt;eos&gt;</td>\n",
       "      <td>[1, 24, 22916, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[973]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11650</th>\n",
       "      <td>vengeance dad</td>\n",
       "      <td>they forgot my birthday</td>\n",
       "      <td>i forgot to stop the car</td>\n",
       "      <td>vengeance-dad.jpg</td>\n",
       "      <td>&lt;sos&gt; you smell &lt;break&gt; step in my shower &lt;eos&gt;</td>\n",
       "      <td>[1, 56, 688, 11, 105, 2, 3, 688, 7, 162, 4, 37...</td>\n",
       "      <td>[758, 231]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56782</th>\n",
       "      <td>family guy pepperidge farm</td>\n",
       "      <td>rts</td>\n",
       "      <td>pepperidge farm remembers</td>\n",
       "      <td>family-guy-pepperidge-farm.jpg</td>\n",
       "      <td>&lt;sos&gt; those nuts are delicious &lt;break&gt; thats w...</td>\n",
       "      <td>[1, 25202, 2, 857, 739, 1276, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[510, 23, 857, 739]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51635</th>\n",
       "      <td>just-lazy-sloth</td>\n",
       "      <td>wakes up from nap in bed</td>\n",
       "      <td>falls asleep on living room couch</td>\n",
       "      <td>just-lazy-sloth.jpg</td>\n",
       "      <td>&lt;sos&gt; everyone is submitting their apps &lt;break...</td>\n",
       "      <td>[1, 2954, 57, 68, 2418, 8, 644, 2, 1890, 1816,...</td>\n",
       "      <td>[1304]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64806</th>\n",
       "      <td>angrydoctor</td>\n",
       "      <td>aids</td>\n",
       "      <td>good luck with that</td>\n",
       "      <td>angrydoctor.jpg</td>\n",
       "      <td>&lt;sos&gt; basketball or game night &lt;break&gt;  &lt;eos&gt;</td>\n",
       "      <td>[1, 1693, 2, 46, 377, 29, 22, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1282]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image                  above_text  \\\n",
       "36402     overly-excited oprah!!!        change your birthday   \n",
       "64258             finnishproblems                      works    \n",
       "61411                  neo matrix          what if i told you   \n",
       "62462                  caixas ss3                        what   \n",
       "33392                 dumb blonde  someone called me a blonde   \n",
       "40523                       gaaay                so hardcoore   \n",
       "11650               vengeance dad     they forgot my birthday   \n",
       "56782  family guy pepperidge farm                         rts   \n",
       "51635             just-lazy-sloth    wakes up from nap in bed   \n",
       "64806                 angrydoctor                        aids   \n",
       "\n",
       "                                           below_text  \\\n",
       "36402  you get cake and you get cake and you get cake   \n",
       "64258                             like a train toilet   \n",
       "61411                          i am actually morpheus   \n",
       "62462                                                   \n",
       "33392                           but i have black hair   \n",
       "40523                                                   \n",
       "11650                        i forgot to stop the car   \n",
       "56782                      pepperidge farm remembers    \n",
       "51635               falls asleep on living room couch   \n",
       "64806                             good luck with that   \n",
       "\n",
       "                            file_path  \\\n",
       "36402        overly-excited-oprah.jpg   \n",
       "64258             finnishproblems.jpg   \n",
       "61411                  neo-matrix.jpg   \n",
       "62462                  caixas-ss3.jpg   \n",
       "33392                 dumb-blonde.jpg   \n",
       "40523                       gaaay.jpg   \n",
       "11650               vengeance-dad.jpg   \n",
       "56782  family-guy-pepperidge-farm.jpg   \n",
       "51635             just-lazy-sloth.jpg   \n",
       "64806                 angrydoctor.jpg   \n",
       "\n",
       "                                            full_caption  \\\n",
       "36402  <sos> uses pit flies under map <break> says he...   \n",
       "64258  <sos> hates old people drivers <break> is old ...   \n",
       "61411  <sos> christmas is a cooked goose <break> so p...   \n",
       "62462  <sos> who can fix it <break> not us of course ...   \n",
       "33392      <sos>  <break> praise the lawd for vtec <eos>   \n",
       "40523       <sos> gooood <break> now give it to me <eos>   \n",
       "11650    <sos> you smell <break> step in my shower <eos>   \n",
       "56782  <sos> those nuts are delicious <break> thats w...   \n",
       "51635  <sos> everyone is submitting their apps <break...   \n",
       "64806      <sos> basketball or game night <break>  <eos>   \n",
       "\n",
       "                                     full_padded_caption      tokenized_label  \n",
       "36402  [1, 603, 17, 105, 2, 5, 47, 1210, 10, 5, 47, 1...         [2825, 2826]  \n",
       "64258  [1, 1740, 2, 41, 6, 1940, 894, 0, 0, 0, 0, 0, ...               [1009]  \n",
       "61411  [1, 33, 20, 3, 71, 5, 2, 3, 142, 458, 574, 0, ...           [938, 334]  \n",
       "62462  [1, 33, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [1233, 1220]  \n",
       "33392  [1, 237, 501, 15, 6, 875, 2, 52, 3, 19, 55, 65...           [402, 875]  \n",
       "40523  [1, 24, 22916, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...                [973]  \n",
       "11650  [1, 56, 688, 11, 105, 2, 3, 688, 7, 162, 4, 37...           [758, 231]  \n",
       "56782  [1, 25202, 2, 857, 739, 1276, 0, 0, 0, 0, 0, 0...  [510, 23, 857, 739]  \n",
       "51635  [1, 2954, 57, 68, 2418, 8, 644, 2, 1890, 1816,...               [1304]  \n",
       "64806  [1, 1693, 2, 46, 377, 29, 22, 0, 0, 0, 0, 0, 0...               [1282]  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_copy.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
