{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up\n",
    "\n",
    "Target vocab size: 40k max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import pickle\n",
    "from pickle_utils import pickle_load, pickle_dump\n",
    "from loadGlove import loadGloveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad lines - return to this later\n",
      "(155392, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54053</th>\n",
       "      <td>My Precious Gollum</td>\n",
       "      <td>Hello TARA...</td>\n",
       "      <td>HELLO PRECIOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67160</th>\n",
       "      <td>Ecstatic Michael Phelps</td>\n",
       "      <td>tHERE'S A POT OF THE STUFF?</td>\n",
       "      <td>i LOVE POT.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49626</th>\n",
       "      <td>katt williams shocked</td>\n",
       "      <td>What</td>\n",
       "      <td>you actually thought you were getting rp?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>Okay Guy</td>\n",
       "      <td>TOOK AN ARROW TO THE KNEE</td>\n",
       "      <td>OKAY..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22047</th>\n",
       "      <td>Rich Men Laughing</td>\n",
       "      <td>and then we told them</td>\n",
       "      <td>their health insurance premiums wouldnt go up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150193</th>\n",
       "      <td>kim jong un</td>\n",
       "      <td>they see me rulin'</td>\n",
       "      <td>they hatin'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121915</th>\n",
       "      <td>The Olympic Queen</td>\n",
       "      <td>vodka</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132328</th>\n",
       "      <td>Paperclip</td>\n",
       "      <td>it looks like you're having trouble</td>\n",
       "      <td>fapping to this meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120444</th>\n",
       "      <td>Honey BooBoo</td>\n",
       "      <td>happy birthday</td>\n",
       "      <td>ali boo boo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15655</th>\n",
       "      <td>Not sure if troll</td>\n",
       "      <td>not sure if nicki minaj</td>\n",
       "      <td>or a mutant from mortal combat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image                           above_text  \\\n",
       "54053        My Precious Gollum                        Hello TARA...   \n",
       "67160   Ecstatic Michael Phelps          tHERE'S A POT OF THE STUFF?   \n",
       "49626     katt williams shocked                                 What   \n",
       "9727                   Okay Guy            TOOK AN ARROW TO THE KNEE   \n",
       "22047         Rich Men Laughing                and then we told them   \n",
       "150193              kim jong un                   they see me rulin'   \n",
       "121915        The Olympic Queen                                vodka   \n",
       "132328                Paperclip  it looks like you're having trouble   \n",
       "120444             Honey BooBoo                       happy birthday   \n",
       "15655         Not sure if troll              not sure if nicki minaj   \n",
       "\n",
       "                                           below_text  \n",
       "54053                                  HELLO PRECIOUS  \n",
       "67160                                     i LOVE POT.  \n",
       "49626       you actually thought you were getting rp?  \n",
       "9727                                           OKAY..  \n",
       "22047   their health insurance premiums wouldnt go up  \n",
       "150193                                    they hatin'  \n",
       "121915                                            NaN  \n",
       "132328                           fapping to this meme  \n",
       "120444                                    ali boo boo  \n",
       "15655                  or a mutant from mortal combat  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = pd.read_csv(\"captions.csv\", error_bad_lines=False, warn_bad_lines=False)\n",
    "print(\"Skipping bad lines - return to this later\")\n",
    "print(captions.shape)\n",
    "captions.sample(10, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create small subsample\n",
    "num_labels = 100\n",
    "random_labels = list(np.random.choice(captions.image.unique(), num_labels))\n",
    "captions = captions[captions['image'].isin(random_labels)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load GloVe and save objects for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_objs = loadGloveModel(\"glove.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_index_dict = glove_objs[0]\n",
    "glove_embedding_weights = glove_objs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1917494, (1917494, 300))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_index_dict), glove_embedding_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_dump(glove_objs, \"glove_objs.pkl\")\n",
    "# glove_objs = pickle_load(\"glove_objs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean captions and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Remove where there are NaNs in the captions or labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image           0\n",
       "above_text    666\n",
       "below_text    954\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pd.isna(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [image, above_text, below_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.iloc[np.where(pd.isna(captions.image))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = captions[pd.notnull(captions.image)]\n",
    "captions = captions.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image         0\n",
       "above_text    0\n",
       "below_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pd.isna(captions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Everything to lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions['image'] = captions['image'].str.lower()\n",
    "captions['above_text'] = captions['above_text'].str.lower()\n",
    "captions['below_text'] = captions['below_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>x all the y</td>\n",
       "      <td>listen to *all*</td>\n",
       "      <td>the bad music!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>joseph ducreux</td>\n",
       "      <td>new born child please enlighten me as to the d...</td>\n",
       "      <td>and cease to inflict pain upon my person ever ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14016</th>\n",
       "      <td>celestia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>what if i told you</td>\n",
       "      <td>what if i told you</td>\n",
       "      <td>instagram doesn't make you a photographer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11521</th>\n",
       "      <td>r. lee ermey</td>\n",
       "      <td>make sure to</td>\n",
       "      <td>vote them all out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>donald trump</td>\n",
       "      <td>we're on some kind of mission we have an oblig...</td>\n",
       "      <td>we have to wear toupees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>socially awkward penguin</td>\n",
       "      <td>try to find word in dictionary</td>\n",
       "      <td>repeat whole albhabet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>pepperidge farm remembers fg</td>\n",
       "      <td>remember when mtv was about music videos not p...</td>\n",
       "      <td>pepperidge farm remembers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11205</th>\n",
       "      <td>neil degrasse tyson reaction</td>\n",
       "      <td>rousseau disagreed with every enlightenment be...</td>\n",
       "      <td>watch out guys we've got a badass over here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>diagnostic house</td>\n",
       "      <td>diagnoses with cancer then gives chemotherapy</td>\n",
       "      <td>conclusion: maybe it wasn\"t cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image  \\\n",
       "5714                    x all the y   \n",
       "888                  joseph ducreux   \n",
       "14016                      celestia   \n",
       "240              what if i told you   \n",
       "11521                  r. lee ermey   \n",
       "4233                   donald trump   \n",
       "1115       socially awkward penguin   \n",
       "4830   pepperidge farm remembers fg   \n",
       "11205  neil degrasse tyson reaction   \n",
       "7079               diagnostic house   \n",
       "\n",
       "                                              above_text  \\\n",
       "5714                                     listen to *all*   \n",
       "888    new born child please enlighten me as to the d...   \n",
       "14016                                                      \n",
       "240                                   what if i told you   \n",
       "11521                                      make sure to    \n",
       "4233   we're on some kind of mission we have an oblig...   \n",
       "1115                      try to find word in dictionary   \n",
       "4830   remember when mtv was about music videos not p...   \n",
       "11205  rousseau disagreed with every enlightenment be...   \n",
       "7079       diagnoses with cancer then gives chemotherapy   \n",
       "\n",
       "                                              below_text  \n",
       "5714                                      the bad music!  \n",
       "888    and cease to inflict pain upon my person ever ...  \n",
       "14016                                                     \n",
       "240            instagram doesn't make you a photographer  \n",
       "11521                                  vote them all out  \n",
       "4233                             we have to wear toupees  \n",
       "1115                               repeat whole albhabet  \n",
       "4830                           pepperidge farm remembers  \n",
       "11205        watch out guys we've got a badass over here  \n",
       "7079                  conclusion: maybe it wasn\"t cancer  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.sample(10, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Remove rows with non-English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for cap in captions.above_text + \" \" + captions.below_text:\n",
    "#     if i < 5:\n",
    "#         for token in cap.split():\n",
    "#             print(token)\n",
    "#         i += 1\n",
    "    \n",
    "# # for word in listofwords\n",
    "# # if not wordnet.synsets(word_to_test):\n",
    "# #   #Not an English Word\n",
    "# # else:\n",
    "# #   #English Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Remove other bad rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine `above_text` and `below_text` here with appropriate breakpoint tokens. Will re-use this later to tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint_captions = \"<sos> \" + captions.above_text + \" <break> \" + captions.below_text + \" <eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 188 rows\n"
     ]
    }
   ],
   "source": [
    "# limit to caption length to under some reasonable upper bound for a meme caption\n",
    "# for many, the scrape just got messed up and appended many captions into one observation\n",
    "longinds = []\n",
    "maxcaplen = 30\n",
    "howmany = 0\n",
    "for i, cap in enumerate(breakpoint_captions):\n",
    "    splitcap = cap.split()\n",
    "    if len(splitcap) > maxcaplen:\n",
    "        longinds.append(i)\n",
    "        howmany += 1\n",
    "captions = captions.drop(captions.index[longinds]).reset_index(drop=True)\n",
    "breakpoint_captions = breakpoint_captions.drop(breakpoint_captions.index[longinds])\n",
    "print(\"Deleted {} rows\".format(howmany))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Clean miscellaneous bad labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions['image'] = captions['image'].str.replace(\"third\",'3rd ')\n",
    "captions['image'] = captions['image'].str.replace(\"3rd -world\",'3rd world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create word mappings\n",
    "\n",
    "Structure borrowed from Harvard IACS 2019 ComputeFest [code](https://github.com/Harvard-IACS/2019-computefest/blob/master/Friday/data_preprocess.ipnb.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(lst):\n",
    "    vocabcount = Counter(w for txt in lst for w in txt.split())\n",
    "    vocab = map(lambda x: x[0], sorted(vocabcount.items(), key=lambda x: -x[1]))\n",
    "    return list(vocab), vocabcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocabcount = get_vocab(list(captions.image) + list(captions.above_text) + list(captions.below_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DELETE WORDS HERE BECAUSE I HAVE VOCAB COUNT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. word2idx and idx2word mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = 1\n",
    "eos = 0  \n",
    "br = 2\n",
    "start_idx = br+1 \n",
    "\n",
    "word2idx = {word: idx+start_idx for idx, word in enumerate(vocab)}\n",
    "word2idx['<sos>'] = sos\n",
    "word2idx['<eos>'] = eos\n",
    "word2idx['<break>'] = br\n",
    "\n",
    "idx2word = {ix: word for word, ix in word2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Form embedding matrix\n",
    "\n",
    "For the words in our observed data, grab the GloVe embeddings. If the word didn't exist in GloVe, initialize it with uniform weights. \n",
    "\n",
    "**Maybe I should be deleting rows where no GloVe embeddings exist?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "embedding_dim = 300\n",
    "shape = (vocab_size, embedding_dim)\n",
    "scale = glove_embedding_weights.std()*np.sqrt(12)/2 \n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)\n",
    "\n",
    "c = 0 # c = number of items w/ GloVe embeddings?\n",
    "for i in range(vocab_size):\n",
    "    w = idx2word[i]\n",
    "    g = glove_index_dict.get(w, glove_index_dict.get(w))\n",
    "    if g is None and w.startswith('#'):\n",
    "        w = w[1:]\n",
    "        g = glove_index_dict.get(w, glove_index_dict.get(w))\n",
    "    if g is not None:\n",
    "        embedding[i,:] = glove_embedding_weights[g,:]\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Create final data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next cells create what should be the data we need. This includes right padding tokenzied captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add padding\n",
    "def rpad(x, maxlen=maxcaplen, eos=eos):\n",
    "    assert maxlen >= 0\n",
    "    if maxlen == 0:\n",
    "        return [eos]\n",
    "    n = len(x)\n",
    "    if n > maxlen:\n",
    "        x = x[-maxlen:]\n",
    "        n = maxlen\n",
    "    return x + [eos]*(maxlen-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_captions = [rpad([word2idx[token] for token in cap.split()]) for cap in breakpoint_captions]                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_images = [[word2idx[token] for token in cap.split()] for cap in captions.image]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"IMAGE LABEL: \", captions.image[24])\n",
    "# print(\"TOKENIZED IMAGE LABEL: \", tokenized_images[24])\n",
    "# print(\"CAPTION: \", captions.above_text[24] + \" \" + captions.below_text[24])\n",
    "# print(\"CAPTION WITH BREAKPOINTS: \", breakpoint_captions[24])\n",
    "# print(\"TOKENIZED CAPTION: \", tokenized_captions[24])\n",
    "# print(\"CAPTION LENGTH: \", len(tokenized_captions[24]))\n",
    "# for token in tokenized_captions[24]:\n",
    "#     print(idx2word[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Validate findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 30, index: 618 \n",
      " <sos> yo dawg i hear you have trouble understanding maths and science <break> so i hired lecturers with thick accents so you can not understand while you don't understand <eos>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFVRJREFUeJzt3XuwnXV97/H3x4Rb0RIokYEkEiwZCzqn6KTIjO0pIxa52ANnRiwebXMoFm2xhx49o6B4uAhH7GlFnVNlUBguWiD1Uqh4RlMFL2MFw13IsUSMEIMkmASJChL4nj+e34bFZq/stXd29ko279fMmr2e3/N7fs/vt57s9Xlu+0mqCknS89sLht0BSdLwGQaSJMNAkmQYSJIwDCRJGAaSJAyD56UkFyX5wBS19ZIkm5LMatM3JnnbVLTd2vu/SZZMVXsTWO95SR5O8tPpXveoftyd5PBt0O6UbqcJrruSHDiMdau/2cPugKZWklXAPsBm4EngHuAK4OKqegqgqt4xgbbeVlX/2q9OVd0PvHDrev30+s4GDqyqt/a0f/RUtD3BfiwA3g3sX1Vrp3G9lwGrq+rMkbKqevl0rX9bSHIj8Jmq+vSw+6It88hgZvrjqnoRsD9wAfBe4JKpXkmSmbozsT/ws+kMAmnoqsrXDHoBq4DXjSo7FHgKeEWbvgw4r73fG/gSsBFYD3yLbifhyrbMr4BNwHuAhUABJwP3A9/sKZvd2rsR+BBwM/AIcC2wV5t3ON2e73P6CxwF/Bp4oq3vjp723tbevwA4E/gxsJbuiGePNm+kH0ta3x4G3r+Fz2mPtvy61t6Zrf3XtTE/1fpxWZ/ljwNuB34O/BA4qpWfBKwAHgXuA97es8zhwGrgfa1/q4C3tHmntLH/uq33X0ZvT2AX4KPAmvb6KLDLqLbf3T6bB4GTtjD+pz/XNv3nrd8bgK/QHRWNzCvgHcC9bf4/AGnzZgF/38bzI+CdI/8egPPpjk4fa2P6PwO0dyDwDbp/Ow8D1wz7d+r58hp6B3xN8QYdIwxa+f3AX7b3l/FMGHwIuAjYqb3+oOcX81lt8cwX7hXA7sBujB0GPwFe0ep8nu40wdNfWP36C5w9Urdn/tNfWu0LayXwUrpTU18ArhzVt0+1fv0u8DhwUJ/P6Qq6oHpRW/bfgZP79XPUsoe2L6s/oguQecDvtHnHAr8NBPhD4JfAq3ra3Qx8hO6L/Q+BXwAvG71d+nw+5wLfBV4MzAW+A3xwVNvntu14TFv3nn3G0Pu5Ht8+14PovsTPBL7TU7fodhjmAC+hC9CR8HsH3anI+cCewL+O8e/hbaPWvaX2rgLe3z7XXYHfH/bv1PPl5Wmi5481wF5jlD8B7Eu3J/hEVX2r2m/lFpxdVb+oql/1mX9lVX2/qn4BfAB408gF5q30FuAjVXVfVW0CzgBOHHW66pyq+lVV3QHcQRcKz9L68ifAGVX1aFWtotu7/dMB+3EycGlVLauqp6rqJ1X1/wCq6vqq+mF1vgF8lS5ge32gqh5v868H3jSB8Z9bVWurah1wzqg+P9HmP1FVX6bbG3/ZAO2+HfhQVa2oqs3A/wIOSbJ/T50LqmpjddeIbgAOaeVvAj5WVauragPdaclB9GvvCbrTdPtV1WNV9e0B29NWMgyeP+bRnQYa7X/T7RV+Ncl9SU4foK0HJjD/x3R7qnsP1Mst26+119v2bLoL5iN67/75JWNf3N4b2HmMtuYN2I8FdKeGniPJ0Um+m2R9ko10e+i9Y9/QQrJ3vfsNuN6xxt+77M/al/mIfuMfbX/gY0k2tj6vpzuy6f08+n2u+/Hs7T3ev43x2ntPW/fN7U6qPx+wPW0lw+B5IMnv0f1iP2cvq+0Zv7uqXgr8MfCuJEeMzO7T5HhHDgt63r+Ebm/vYbpTIr/R069ZdKc7Bm13Dd0XV2/bm4GHxllutId5Zg+0t62fDLj8A3Sngp4lyS50p8X+DtinquYAX6b7chuxZ5LdR613TXs/mfGv6VN3Ih6gu7Yxp+e1W1V9Z4BlH6Q7RTRiwaj5E3osclX9tKr+oqr2ozti+YS3oU4Pw2AGS/KbSd4AXE13Lv6uMeq8IcmBSUJ3MfTJ9oLuS/alk1j1W5McnOQ36M5hf66qnqQ7L79rkmOT7ER3bnqXnuUeAhYm6ffv8irgvyc5IMkL6U5nXDNqb3hcrS9LgfOTvKidDnkX8JkBm7gEOCnJEUlekGRekt+hO9rYhe4c+OYkRwNHjrH8OUl2TvIHwBuAf2rl433eVwFnJpmbZG/gf06gz1tyEXBGkpcDJNkjyQkDLrsUOK19BnPo7lzrNaF/Q0lOSDISLhvowuTJLSyiKWIYzEz/kuRRuj2+99NdsDypT91FdBf9NgH/Bnyiqm5s8z5E9+WzMcn/mMD6r6S7GPpTuouA/w2gqh4B/gr4NN1e+C/o7oAZMfKl+LMkt47R7qWt7W/S3bnyGPDXE+hXr79u67+P7ojpH1v746qqm+k+zwvpLiR/g+6ay6N0Y11K90X2X4DrRi3+0zZvDfBZ4B0j1xvoQubg9nn/8xirPg9YDtwJ3AXc2sq2SlV9EfgwcHWSnwPfBwb9+45P0V0XuRO4je5IaORvXAA+BrwxyYYkHx+gvd8Dbkqyie6zO62qfjTwYDRpI3eNSNrG2l8Sf6aq5o9Xd0fVjoYuqqr9x62s7YpHBpImLcluSY5JMjvJPOAs4IvD7pcmzjCQtDVCd4vrBrrTRCvormVoB+NpIkmSRwaSpO38qaV77713LVy4cNjdkKQdyi233PJwVc0dv+YztuswWLhwIcuXLx92NyRph5Lkx+PXejZPE0mSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkie38L5A1HAtPv34o6111wbFDWa8kjwwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSmEAYJJmV5LYkX2rTByS5Kcm9Sa5JsnMr36VNr2zzF/a0cUYr/0GS10/1YCRJkzORI4PTgBU90x8GLqyqRcAG4ORWfjKwoaoOBC5s9UhyMHAi8HLgKOATSWZtXfclSVNhoDBIMh84Fvh0mw7wWuBzrcrlwPHt/XFtmjb/iFb/OODqqnq8qn4ErAQOnYpBSJK2zqBHBh8F3gM81aZ/C9hYVZvb9GpgXns/D3gAoM1/pNV/unyMZZ6W5JQky5MsX7du3QSGIkmarHHDIMkbgLVVdUtv8RhVa5x5W1rmmYKqi6tqcVUtnjt37njdkyRNgdkD1HkN8J+SHAPsCvwm3ZHCnCSz297/fGBNq78aWACsTjIb2ANY31M+oncZSdIQjXtkUFVnVNX8qlpIdwH461X1FuAG4I2t2hLg2vb+ujZNm//1qqpWfmK72+gAYBFw85SNRJI0aYMcGfTzXuDqJOcBtwGXtPJLgCuTrKQ7IjgRoKruTrIUuAfYDJxaVU9uxfolSVNkQmFQVTcCN7b39zHG3UBV9RhwQp/lzwfOn2gnJUnbln+BLEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSgNnD7oD6W3j69cPugqTnCY8MJEmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIYIAyS7Jrk5iR3JLk7yTmt/IAkNyW5N8k1SXZu5bu06ZVt/sKets5o5T9I8vptNShJ0sQMcmTwOPDaqvpd4BDgqCSHAR8GLqyqRcAG4ORW/2RgQ1UdCFzY6pHkYOBE4OXAUcAnksyaysFIkiZn3DCozqY2uVN7FfBa4HOt/HLg+Pb+uDZNm39EkrTyq6vq8ar6EbASOHRKRiFJ2ioDXTNIMivJ7cBaYBnwQ2BjVW1uVVYD89r7ecADAG3+I8Bv9ZaPsUzvuk5JsjzJ8nXr1k18RJKkCRsoDKrqyao6BJhPtzd/0FjV2s/0mdevfPS6Lq6qxVW1eO7cuYN0T5K0lSb0P51V1cYkNwKHAXOSzG57//OBNa3aamABsDrJbGAPYH1P+YjeZaShGdb/KLfqgmOHsl5pLIPcTTQ3yZz2fjfgdcAK4Abgja3aEuDa9v66Nk2b//WqqlZ+Yrvb6ABgEXDzVA1EkjR5gxwZ7Atc3u78eQGwtKq+lOQe4Ook5wG3AZe0+pcAVyZZSXdEcCJAVd2dZClwD7AZOLWqnpza4UiSJmPcMKiqO4FXjlF+H2PcDVRVjwEn9GnrfOD8iXdTkrQt+RfIkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAksQEn00kbUvDekaQJI8MJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkBgiDJAuS3JBkRZK7k5zWyvdKsizJve3nnq08ST6eZGWSO5O8qqetJa3+vUmWbLthSZImYpAjg83Au6vqIOAw4NQkBwOnA1+rqkXA19o0wNHAovY6BfgkdOEBnAW8GjgUOGskQCRJwzVuGFTVg1V1a3v/KLACmAccB1zeql0OHN/eHwdcUZ3vAnOS7Au8HlhWVeuragOwDDhqSkcjSZqUCV0zSLIQeCVwE7BPVT0IXWAAL27V5gEP9Cy2upX1K5ckDdnAYZDkhcDngb+pqp9vqeoYZbWF8tHrOSXJ8iTL161bN2j3JElbYaAwSLITXRB8tqq+0Iofaqd/aD/XtvLVwIKexecDa7ZQ/ixVdXFVLa6qxXPnzp3IWCRJkzTI3UQBLgFWVNVHemZdB4zcEbQEuLan/M/aXUWHAY+000hfAY5Msme7cHxkK5MkDdnsAeq8BvhT4K4kt7ey9wEXAEuTnAzcD5zQ5n0ZOAZYCfwSOAmgqtYn+SDwvVbv3KpaPyWjkCRtlXHDoKq+zdjn+wGOGKN+Aaf2aetS4NKJdFCStO35F8iSJMNAkmQYSJIY7AKypG1g4enXD23dqy44dmjr1vbJIwNJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYoAwSHJpkrVJvt9TtleSZUnubT/3bOVJ8vEkK5PcmeRVPcssafXvTbJk2wxHkjQZgxwZXAYcNarsdOBrVbUI+FqbBjgaWNRepwCfhC48gLOAVwOHAmeNBIgkafjGDYOq+iawflTxccDl7f3lwPE95VdU57vAnCT7Aq8HllXV+qraACzjuQEjSRqSyV4z2KeqHgRoP1/cyucBD/TUW93K+pU/R5JTkixPsnzdunWT7J4kaSKm+gJyxiirLZQ/t7Dq4qpaXFWL586dO6WdkySNbfYkl3soyb5V9WA7DbS2la8GFvTUmw+saeWHjyq/cZLrnnYLT79+2F2QpG1qskcG1wEjdwQtAa7tKf+zdlfRYcAj7TTSV4Ajk+zZLhwf2cokSduBcY8MklxFt1e/d5LVdHcFXQAsTXIycD9wQqv+ZeAYYCXwS+AkgKpan+SDwPdavXOravRFaUnSkIwbBlX15j6zjhijbgGn9mnnUuDSCfVOkjQt/AtkSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgSWLyzyaStAMb1vO2Vl1w7FDWq/F5ZCBJMgwkSYaBJAnDQJKEYSBJwjCQJOGtpZKmkbe0br88MpAkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwgfVSXoe8AF54/PIQJJkGEiSDANJEl4zkKRtZljXKibDIwNJkmEgSTIMJEkMIQySHJXkB0lWJjl9utcvSXquaQ2DJLOAfwCOBg4G3pzk4OnsgyTpuab7yOBQYGVV3VdVvwauBo6b5j5IkkaZ7ltL5wEP9EyvBl7dWyHJKcApbfLxJN+fpr4Nw97Aw8PuxDbk+HZsM3l8M3lsAC+b6ALTHQYZo6yeNVF1MXAxQJLlVbV4Ojo2DI5vx+b4dlwzeWzQjW+iy0z3aaLVwIKe6fnAmmnugyRplOkOg+8Bi5IckGRn4ETgumnugyRplGk9TVRVm5O8E/gKMAu4tKru3sIiF09Pz4bG8e3YHN+OayaPDSYxvlTV+LUkSTOaf4EsSTIMJEnbcRjM9MdWJFmV5K4kt0/mNrDtTZJLk6zt/buQJHslWZbk3vZzz2H2cbL6jO3sJD9p2+/2JMcMs49bI8mCJDckWZHk7iSntfKZsv36jW9GbMMkuya5OckdbXzntPIDktzUtt817aad/u1sj9cM2mMr/h34I7rbUb8HvLmq7hlqx6ZQklXA4qqaEX/4kuQ/ApuAK6rqFa3sb4H1VXVBC/Q9q+q9w+znZPQZ29nApqr6u2H2bSok2RfYt6puTfIi4BbgeOC/MjO2X7/xvYkZsA2TBNi9qjYl2Qn4NnAa8C7gC1V1dZKLgDuq6pP92tlejwx8bMUOpqq+CawfVXwccHl7fzndL+AOp8/YZoyqerCqbm3vHwVW0D0tYKZsv37jmxGqs6lN7tReBbwW+FwrH3f7ba9hMNZjK2bMxmsK+GqSW9ojOGaifarqQeh+IYEXD7k/U+2dSe5sp5F2yFMooyVZCLwSuIkZuP1GjQ9myDZMMivJ7cBaYBnwQ2BjVW1uVcb9Dt1ew2Dcx1bMAK+pqlfRPcH11HYqQjuOTwK/DRwCPAj8/XC7s/WSvBD4PPA3VfXzYfdnqo0xvhmzDavqyao6hO6pDocCB41VbUttbK9hMOMfW1FVa9rPtcAX6TbgTPNQO187ct527ZD7M2Wq6qH2C/gU8Cl28O3XzjV/HvhsVX2hFc+Y7TfW+GbaNgSoqo3AjcBhwJwkI39YPO536PYaBjP6sRVJdm8XskiyO3AkMBOfznodsKS9XwJcO8S+TKmRL8nmP7MDb792AfISYEVVfaRn1ozYfv3GN1O2YZK5Sea097sBr6O7LnID8MZWbdztt13eTQTQbvP6KM88tuL8IXdpyiR5Kd3RAHSPBPnHHX18Sa4CDqd7NPBDwFnAPwNLgZcA9wMnVNUOdyG2z9gOpzu9UMAq4O0j59d3NEl+H/gWcBfwVCt+H9159Zmw/fqN783MgG2Y5D/QXSCeRbeDv7Sqzm3fM1cDewG3AW+tqsf7trO9hoEkafpsr6eJJEnTyDCQJBkGkiTDQJKEYSBJwjCQJGEYSJKA/w9pDqd8N0U0nwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxlen = 0\n",
    "longcap = \"\"\n",
    "ind = 0\n",
    "lens = []\n",
    "for i, cap in enumerate(breakpoint_captions):\n",
    "    splitcap = cap.split()\n",
    "    lens.append(len(splitcap))\n",
    "    if len(splitcap) > maxlen:\n",
    "        maxlen = len(splitcap)\n",
    "        longcap = cap\n",
    "        ind = i\n",
    "print(\"Length: {}, index: {} \\n {}\".format(maxlen, ind, longcap))\n",
    "plt.hist(lens)\n",
    "plt.xlim([0, 30])\n",
    "plt.title(\"Distribution of caption lengths\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_copy = captions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_junk(x):\n",
    "    illegal = [\"?\", \"'\", \" /\", \"[\", \"]\", \".\", \"á\", \" -\", \"*\", \"/\", \"!\", \n",
    "               \"ñ\", \"í\", \"(\", \")\", \"$\", \"\\\"\", \"`\", \":\", \";\"]\n",
    "    end_illegal = [' ', '-']\n",
    "    impute_chars = ['- ',' ', '_']\n",
    "    \n",
    "    for char in end_illegal:\n",
    "        while x[-1] == char:  # strip off illegal end characters\n",
    "            x = x[:-1]\n",
    "        \n",
    "    \n",
    "    for char in illegal:\n",
    "        if char in x:  # strip off overall illegal characters\n",
    "            x = x.replace(char, \"\")\n",
    "        \n",
    "    for char in impute_chars: # impute certain characters\n",
    "        x = x.replace(char, \"-\")\n",
    "    return x + \".jpg\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill out csv\n",
    "captions_copy['file_path'] = captions_copy['image'].apply(strip_junk)\n",
    "captions_copy['full_caption'] = breakpoint_captions\n",
    "captions_copy['full_padded_caption'] = pd.Series((cap for cap in tokenized_captions))\n",
    "captions_copy['tokenized_label'] = tokenized_images\n",
    "captions_copy['image'] = captions_copy['image'].apply(lambda x: x.strip(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=63352285...\n",
      "writing bytes [0, 63352285)... done.\n"
     ]
    }
   ],
   "source": [
    "out_file = \"small_processed_data.pkl\"\n",
    "out_objs = (embedding, idx2word, word2idx, captions_copy)\n",
    "pickle_dump(out_objs, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
