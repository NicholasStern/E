{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meme Caption Generator\n",
    "## Data Processing\n",
    "Anthony Rentsch, Nicholas Stern, Lipika Ramaswamy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we do all of the necessary data processing for the Meme Generator data that we scraped using the `meme_generator_scraper.py` file. We follow the lead of the paper [Dank Learning](https://arxiv.org/pdf/1806.04510.pdf) throughout. We do make some decisions that cut down on the size of our dataset, but we feel that those are okay because training our model takes a long time even with a smaller subset.\n",
    "\n",
    "This notebook is set up as follows:\n",
    "\n",
    "0. [**Set up**](#setup)\n",
    "1. [**Load GloVe embeddings**](#glove)\n",
    "2. [**Clean captions and labels**](#cleaning)\n",
    "3. [**Create word mappings**](#finalmap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up<a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "#nltk.download('words')\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import pickle\n",
    "from pickle_utils import pickle_load, pickle_dump\n",
    "from loadGlove import loadGloveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 155392.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54053</th>\n",
       "      <td>My Precious Gollum</td>\n",
       "      <td>Hello TARA...</td>\n",
       "      <td>HELLO PRECIOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67160</th>\n",
       "      <td>Ecstatic Michael Phelps</td>\n",
       "      <td>tHERE'S A POT OF THE STUFF?</td>\n",
       "      <td>i LOVE POT.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49626</th>\n",
       "      <td>katt williams shocked</td>\n",
       "      <td>What</td>\n",
       "      <td>you actually thought you were getting rp?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>Okay Guy</td>\n",
       "      <td>TOOK AN ARROW TO THE KNEE</td>\n",
       "      <td>OKAY..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22047</th>\n",
       "      <td>Rich Men Laughing</td>\n",
       "      <td>and then we told them</td>\n",
       "      <td>their health insurance premiums wouldnt go up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150193</th>\n",
       "      <td>kim jong un</td>\n",
       "      <td>they see me rulin'</td>\n",
       "      <td>they hatin'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121915</th>\n",
       "      <td>The Olympic Queen</td>\n",
       "      <td>vodka</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132328</th>\n",
       "      <td>Paperclip</td>\n",
       "      <td>it looks like you're having trouble</td>\n",
       "      <td>fapping to this meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120444</th>\n",
       "      <td>Honey BooBoo</td>\n",
       "      <td>happy birthday</td>\n",
       "      <td>ali boo boo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15655</th>\n",
       "      <td>Not sure if troll</td>\n",
       "      <td>not sure if nicki minaj</td>\n",
       "      <td>or a mutant from mortal combat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image                           above_text  \\\n",
       "54053        My Precious Gollum                        Hello TARA...   \n",
       "67160   Ecstatic Michael Phelps          tHERE'S A POT OF THE STUFF?   \n",
       "49626     katt williams shocked                                 What   \n",
       "9727                   Okay Guy            TOOK AN ARROW TO THE KNEE   \n",
       "22047         Rich Men Laughing                and then we told them   \n",
       "150193              kim jong un                   they see me rulin'   \n",
       "121915        The Olympic Queen                                vodka   \n",
       "132328                Paperclip  it looks like you're having trouble   \n",
       "120444             Honey BooBoo                       happy birthday   \n",
       "15655         Not sure if troll              not sure if nicki minaj   \n",
       "\n",
       "                                           below_text  \n",
       "54053                                  HELLO PRECIOUS  \n",
       "67160                                     i LOVE POT.  \n",
       "49626       you actually thought you were getting rp?  \n",
       "9727                                           OKAY..  \n",
       "22047   their health insurance premiums wouldnt go up  \n",
       "150193                                    they hatin'  \n",
       "121915                                            NaN  \n",
       "132328                           fapping to this meme  \n",
       "120444                                    ali boo boo  \n",
       "15655                  or a mutant from mortal combat  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = pd.read_csv(\"captions.csv\", error_bad_lines=False, warn_bad_lines=False)\n",
    "print(\"Number of observations: {}.\".format(captions.shape[0]))\n",
    "captions.sample(10, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our captions are split up into two pieces: the `above_text`, the piece of the meme caption that is located above the base image, and the `below_text`, the piece of the caption that is located below the base image. This follows from a recommendation in the original Dank Learning paper that we follow to predict both parts of the caption rather than the full concatenated caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create small subsample\n",
    "# num_labels = 100\n",
    "# random_labels = list(np.random.choice(captions.image.unique(), num_labels))\n",
    "# captions = captions[captions['image'].isin(random_labels)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load GloVe word embeddings <a name=\"glove\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downloaded the one of the pre-trained Global Vectors for Word Representation embeddings (i.e., GloVe embeddings) from Stanford NLP's [website](https://nlp.stanford.edu/projects/glove/). We use the vectors trained on a Common Cralw dataset with 42 billion tokens and a vocabulary size of 1.9 million words. The vectors, essentially a latent representation of each of the 1.9 million words, are 300-dimensional. \n",
    "\n",
    "We wrote a helper function (found in `loadGlove.py`) to turn the downloaded .txt file into two helpful objects:\n",
    "- a matrix where each row corresponds to the GloVe embedding for one word\n",
    "- a dictionary that maps words to their index in the embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_objs = loadGloveModel(\"glove.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_index_dict = glove_objs[0]\n",
    "glove_embedding_weights = glove_objs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1917494, (1917494, 300))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_index_dict), glove_embedding_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_dump(glove_objs, \"glove_objs.pkl\")\n",
    "# glove_objs = pickle_load(\"glove_objs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean captions and labels <a name=\"cleaning\"></a>\n",
    "\n",
    "Since we are scraping plain text that is input by users of Meme Generator, there is a lot of cleaning to be done. The following sub-sections perform various cleaning operations, ranging from discarding images with missing image labels to filtering out captions that contain offensive words or phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Remove rows when there are NaNs in the captions or labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image           13\n",
       "above_text    6137\n",
       "below_text    7199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pd.isna(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18546</th>\n",
       "      <td>NaN</td>\n",
       "      <td>several people get up and leave as they can se...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43899</th>\n",
       "      <td>NaN</td>\n",
       "      <td>teacher is even later than you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57525</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ekki málið :)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100719</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ert þú starfsmaður þarna eða eigandi?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100723</th>\n",
       "      <td>NaN</td>\n",
       "      <td>uppiskorpi!!!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100725</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Eða bara eldisfiskur. LOL.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100728</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Takk kærlega fyrir þetta :)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>makes us strong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>makes us strong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114690</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Nei þá nærðu í rauðvín</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114721</th>\n",
       "      <td>NaN</td>\n",
       "      <td>merkileg blanda alveg;)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115828</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Fannst þetta bara krúttleg mynd =)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I NEVER ASK FOR THIS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image                                         above_text below_text\n",
       "18546    NaN  several people get up and leave as they can se...        NaN\n",
       "43899    NaN                     teacher is even later than you        NaN\n",
       "57525    NaN                                      Ekki málið :)        NaN\n",
       "100719   NaN              Ert þú starfsmaður þarna eða eigandi?        NaN\n",
       "100723   NaN                                      uppiskorpi!!!        NaN\n",
       "100725   NaN                         Eða bara eldisfiskur. LOL.        NaN\n",
       "100728   NaN                        Takk kærlega fyrir þetta :)        NaN\n",
       "105241   NaN                                    makes us strong        NaN\n",
       "105243   NaN                                    makes us strong        NaN\n",
       "114690   NaN                             Nei þá nærðu í rauðvín        NaN\n",
       "114721   NaN                            merkileg blanda alveg;)        NaN\n",
       "115828   NaN                 Fannst þetta bara krúttleg mynd =)        NaN\n",
       "132127   NaN                               I NEVER ASK FOR THIS        NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.iloc[np.where(pd.isna(captions.image))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = captions[pd.notnull(captions.image)]\n",
    "captions = captions.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image         0\n",
       "above_text    0\n",
       "below_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pd.isna(captions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Convert all captions and labels to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions['image'] = captions['image'].str.lower()\n",
    "captions['above_text'] = captions['above_text'].str.lower()\n",
    "captions['below_text'] = captions['below_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>above_text</th>\n",
       "      <th>below_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148743</th>\n",
       "      <td>bender popular</td>\n",
       "      <td>todos se iban a paro</td>\n",
       "      <td>la usm solo quería ser popular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60086</th>\n",
       "      <td>uncle dolan pls</td>\n",
       "      <td>clovhy pls</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81607</th>\n",
       "      <td>lawn chair blown over</td>\n",
       "      <td>cerberus earthquake 2012</td>\n",
       "      <td>we will rebuild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79323</th>\n",
       "      <td>pizzeria los hijos de puta</td>\n",
       "      <td>y monsters university?</td>\n",
       "      <td>para cuando monsters university?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42541</th>\n",
       "      <td>liberal douche garofalo</td>\n",
       "      <td>overregulates everything into complete disfunc...</td>\n",
       "      <td>defends it as \"the new normal\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>joker mind loss</td>\n",
       "      <td>a girl kiss a girl in public and no one bats a...</td>\n",
       "      <td>a boy kiss a boy in public and everyone loses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152361</th>\n",
       "      <td>over obsessive girlfriend</td>\n",
       "      <td>why</td>\n",
       "      <td>is sleep more important than me kim?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142516</th>\n",
       "      <td>tony horton</td>\n",
       "      <td>recovery week</td>\n",
       "      <td>it's a beautiful thing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42871</th>\n",
       "      <td>mens wearhouse</td>\n",
       "      <td>you're gonna like how the site looks</td>\n",
       "      <td>i guarantee it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7923</th>\n",
       "      <td>butthurt dweller</td>\n",
       "      <td>talk shit on internet</td>\n",
       "      <td>feel superior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image  \\\n",
       "148743              bender popular   \n",
       "60086              uncle dolan pls   \n",
       "81607        lawn chair blown over   \n",
       "79323   pizzeria los hijos de puta   \n",
       "42541      liberal douche garofalo   \n",
       "6074               joker mind loss   \n",
       "152361   over obsessive girlfriend   \n",
       "142516                 tony horton   \n",
       "42871               mens wearhouse   \n",
       "7923              butthurt dweller   \n",
       "\n",
       "                                               above_text  \\\n",
       "148743                               todos se iban a paro   \n",
       "60086                                          clovhy pls   \n",
       "81607                            cerberus earthquake 2012   \n",
       "79323                              y monsters university?   \n",
       "42541   overregulates everything into complete disfunc...   \n",
       "6074    a girl kiss a girl in public and no one bats a...   \n",
       "152361                                                why   \n",
       "142516                                      recovery week   \n",
       "42871                you're gonna like how the site looks   \n",
       "7923                                talk shit on internet   \n",
       "\n",
       "                                               below_text  \n",
       "148743                     la usm solo quería ser popular  \n",
       "60086                                                      \n",
       "81607                                     we will rebuild  \n",
       "79323                   para cuando monsters university?!  \n",
       "42541                      defends it as \"the new normal\"  \n",
       "6074    a boy kiss a boy in public and everyone loses ...  \n",
       "152361               is sleep more important than me kim?  \n",
       "142516                            it's a beautiful thing!  \n",
       "42871                                      i guarantee it  \n",
       "7923                                        feel superior  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.sample(10, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Remove rows with non-English or offensive words\n",
    "\n",
    "We noticed that many captions were in other languages, particularly Spanish and Russian. We wish to get rid of these in our final dataset, so we filter out all captions with words that do not appear in the words in GloVe (which are all English words). This is a rather harsh criteria and we do remove some captions with English words that simply do not show up in GloVe.\n",
    "\n",
    "Additionally, we wish to filter out as much offensive content as we can. We noticed that many of the memes from Meme Generator contained hateful content and we would not like to perpetuate this type of content in our project. This is an extension recommended by the authors of Dank Learning.\n",
    "\n",
    "We filter out words in our training set that contain any words from a [list](https://gist.github.com/jamiew/1112488) of \"bad words\" compiled as a part of Google's \"What Do You Love\" project. The idea to filter out words from this list comes from a [paper](https://www.usenix.org/system/files/conference/foci17/foci17-paper-nithyanand.pdf) which attempted to measure offensive speech in political discourse on Reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-English words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_words = set(list(glove_index_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72453 observations deleted because they contain non-English words.\n"
     ]
    }
   ],
   "source": [
    "nonenglishinds = []\n",
    "i = 0\n",
    "for ind, cap in enumerate(captions.above_text + \" \" + captions.below_text):\n",
    "    for word in cap.split():\n",
    "        if word not in glove_words:\n",
    "            nonenglishinds.append(ind)\n",
    "\n",
    "nonenglishinds = list(set(nonenglishinds))           \n",
    "print(\"{} observations deleted because they contain non-English words.\".format(len(nonenglishinds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = captions.drop(captions.index[nonenglishinds]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Offensive words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badwords = []\n",
    "i = 1\n",
    "google_wdyl_path = \"google_twunter_lol.txt\"\n",
    "with open(google_wdyl_path, 'r') as f:\n",
    "    for line in f:\n",
    "        for word in line.split(\":\"):\n",
    "            if i % 2 == 0:\n",
    "                badwords.append(word.replace('\"', \"\"))\n",
    "            i += 1\n",
    "badwords.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10641 observations deleted because they contain bad words.\n"
     ]
    }
   ],
   "source": [
    "badwordinds = []\n",
    "i = 0\n",
    "for ind, cap in enumerate(captions.above_text + \" \" + captions.below_text):\n",
    "    for word in cap.split():\n",
    "        if word in badwords:\n",
    "            badwordinds.append(ind)\n",
    "print(\"{} observations deleted because they contain bad words.\".format(len(badwordinds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = captions.drop(captions.index[badwordinds]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Remove other bad rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we combine `above_text` and `below_text` here with appropriate breakpoint tokens. This will be re-used later when we tokenize the captions. For now, this lets us filter out captions that are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint_captions = \"<sos> \" + captions.above_text + \" <break> \" + captions.below_text + \" <eos>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We limit to caption length to under some reasonable upper bound for a meme caption. We set that threshold to 20. For many, the scrape just got messed up and appended many captions into one observation. We simply discard these rows, which are a small subset of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 3525 rows for being too long.\n"
     ]
    }
   ],
   "source": [
    "longinds = []\n",
    "maxcaplen = 20\n",
    "howmany = 0\n",
    "for i, cap in enumerate(breakpoint_captions):\n",
    "    splitcap = cap.split()\n",
    "    if len(splitcap) > maxcaplen:\n",
    "        longinds.append(i)\n",
    "        howmany += 1\n",
    "captions = captions.drop(captions.index[longinds]).reset_index(drop=True)\n",
    "breakpoint_captions = breakpoint_captions.drop(breakpoint_captions.index[longinds])\n",
    "print(\"Deleted {} rows for being too long.\".format(howmany))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Clean miscellaneous bad labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions['image'] = captions['image'].str.replace(\"third\",'3rd ')\n",
    "captions['image'] = captions['image'].str.replace(\"3rd -world\",'3rd world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After all of this cleaning we are left with 70122 observations.\n"
     ]
    }
   ],
   "source": [
    "print(\"After all of this cleaning we are left with {} observations.\".format(captions.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create word mappings<a name=\"finalmap\"></a>\n",
    "\n",
    "Finally, we go ahead and create the data objects we need to train our model. This includes:\n",
    "\n",
    "- word2idx and idx2word mappings for the words in our vocabulary\n",
    "- embeddings matrix for the words in our vocabulary\n",
    "- tokenized and padded captions and image labels\n",
    "\n",
    "The structure for this section is borrowed from Harvard IACS 2019 ComputeFest [code](https://github.com/Harvard-IACS/2019-computefest/blob/master/Friday/data_preprocess.ipnb.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(lst):\n",
    "    vocabcount = Counter(w for txt in lst for w in txt.split())\n",
    "    vocab = map(lambda x: x[0], sorted(vocabcount.items(), key=lambda x: -x[1]))\n",
    "    return list(vocab), vocabcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocabcount = get_vocab(list(captions.image) + list(captions.above_text) + list(captions.below_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 36706\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. word2idx and idx2word mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = 1\n",
    "eos = 0  \n",
    "br = 2\n",
    "start_idx = br+1 \n",
    "\n",
    "word2idx = {word: idx+start_idx for idx, word in enumerate(vocab)}\n",
    "word2idx['<sos>'] = sos\n",
    "word2idx['<eos>'] = eos\n",
    "word2idx['<break>'] = br\n",
    "\n",
    "idx2word = {ix: word for word, ix in word2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Form embedding matrix\n",
    "\n",
    "For the words in our observed data, store the GloVe embeddings in a matrix. If the word didn't exist in GloVe, initialize it with uniform weights. This should not be the case since we filter out words that don't exist in GloVe, but we do this to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "embedding_dim = 300\n",
    "shape = (vocab_size, embedding_dim)\n",
    "scale = glove_embedding_weights.std()*np.sqrt(12)/2 \n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)\n",
    "\n",
    "c = 0\n",
    "for i in range(vocab_size):\n",
    "    w = idx2word[i]\n",
    "    g = glove_index_dict.get(w, glove_index_dict.get(w))\n",
    "    if g is None and w.startswith('#'):\n",
    "        w = w[1:]\n",
    "        g = glove_index_dict.get(w, glove_index_dict.get(w))\n",
    "    if g is not None:\n",
    "        embedding[i,:] = glove_embedding_weights[g,:]\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Create final data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next cells create what should be the input data we need. This includes right padded tokenzied captions and image labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpad(x, maxlen=maxcaplen, eos=eos):\n",
    "    assert maxlen >= 0\n",
    "    if maxlen == 0:\n",
    "        return [eos]\n",
    "    n = len(x)\n",
    "    if n > maxlen:\n",
    "        x = x[-maxlen:]\n",
    "        n = maxlen\n",
    "    return x + [eos]*(maxlen-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_captions = [rpad([word2idx[token] for token in cap.split()]) for cap in breakpoint_captions]                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_images = [[word2idx[token] for token in cap.split()] for cap in captions.image]   \n",
    "tokenized_padded_images = [rpad([word2idx[token] for token in cap.split()]) for cap in captions.image]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to make sure these were all created appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE LABEL:  y u no\n",
      "TOKENIZED IMAGE LABEL:  [92, 72, 21]\n",
      "CAPTION:  justin bieber y u no dead\n",
      "CAPTION WITH BREAKPOINTS:  <sos> justin bieber <break> y u no dead <eos>\n",
      "TOKENIZED CAPTION:  [1, 304, 446, 2, 92, 72, 21, 176, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CAPTION LENGTH:  20\n",
      "<sos>\n",
      "justin\n",
      "bieber\n",
      "<break>\n",
      "y\n",
      "u\n",
      "no\n",
      "dead\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "print(\"IMAGE LABEL: \", captions.image[24])\n",
    "print(\"TOKENIZED IMAGE LABEL: \", tokenized_images[24])\n",
    "print(\"CAPTION: \", captions.above_text[24] + \" \" + captions.below_text[24])\n",
    "print(\"CAPTION WITH BREAKPOINTS: \", breakpoint_captions[24])\n",
    "print(\"TOKENIZED CAPTION: \", tokenized_captions[24])\n",
    "print(\"CAPTION LENGTH: \", len(tokenized_captions[24]))\n",
    "for token in tokenized_captions[24]:\n",
    "    print(idx2word[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Validate findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max caption length: 20, index of longest caption: 67\n",
      "Caption: <sos> memegenerator <break> y u no let me see what memes i have created and what memes i like <eos>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxlen = 0\n",
    "longcap = \"\"\n",
    "ind = 0\n",
    "lens = []\n",
    "for i, cap in enumerate(breakpoint_captions):\n",
    "    splitcap = cap.split()\n",
    "    lens.append(len(splitcap))\n",
    "    if len(splitcap) > maxlen:\n",
    "        maxlen = len(splitcap)\n",
    "        longcap = cap\n",
    "        ind = i\n",
    "print(\"Max caption length: {}, index of longest caption: {}\\nCaption: {}\".format(maxlen, ind, longcap))\n",
    "plt.hist(lens)\n",
    "plt.xlim([0, 25])\n",
    "plt.title(\"Distribution of caption lengths\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_copy = captions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_junk(x):\n",
    "    '''\n",
    "    Get rid of bad punctuation and spaces in the image labels.\n",
    "    '''\n",
    "    illegal = [\"?\", \"'\", \" /\", \"[\", \"]\", \".\", \"á\", \" -\", \"*\", \"/\", \"!\", \n",
    "               \"ñ\", \"í\", \"(\", \")\", \"$\", \"\\\"\", \"`\", \":\", \";\"]\n",
    "    end_illegal = [' ', '-']\n",
    "    impute_chars = ['- ',' ', '_']\n",
    "    \n",
    "    for char in end_illegal:\n",
    "        while x[-1] == char:  # strip off illegal end characters\n",
    "            x = x[:-1]\n",
    "    \n",
    "    for char in illegal:\n",
    "        if char in x:  # strip off overall illegal characters\n",
    "            x = x.replace(char, \"\")\n",
    "        \n",
    "    for char in impute_chars: # impute certain characters\n",
    "        x = x.replace(char, \"-\")\n",
    "    return x + \".jpg\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill out rest of captions.csv\n",
    "captions_copy['file_path'] = captions_copy['image'].apply(strip_junk)\n",
    "captions_copy['full_caption'] = breakpoint_captions\n",
    "captions_copy['full_padded_caption'] = pd.Series((cap for cap in tokenized_captions))\n",
    "captions_copy['tokenized_label'] = tokenized_images\n",
    "captions_copy['tokenized_padded_label'] = tokenized_padded_images\n",
    "captions_copy['image'] = captions_copy['image'].apply(lambda x: x.strip(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=106654863...\n",
      "writing bytes [0, 106654863)... done.\n"
     ]
    }
   ],
   "source": [
    "out_file = \"full_clean_processed_data.pkl\"\n",
    "out_objs = (embedding, idx2word, word2idx, captions_copy)\n",
    "pickle_dump(out_objs, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
