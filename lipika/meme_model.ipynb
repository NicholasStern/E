{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, RepeatVector, Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "os.chdir('../Anthony/')\n",
    "from pickle_utils import pickle_load, pickle_dump\n",
    "os.chdir('../lipika/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding shit\n",
    "glove_index_dict, embeddings = pickle_load(\"../Anthony/glove_objs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "img_shape = (300,300,3)\n",
    "vocab_size = embeddings.shape[0]\n",
    "embedding_size = 300\n",
    "maxlen = 20                         # maximum length of the caption in hidden state\n",
    "\n",
    "hidden_units = embedding_size       # length of word vectors i.e. embedding size\n",
    "en_shape = maxlen\n",
    "de_shape = maxlen\n",
    "\n",
    "# hyper params\n",
    "clip_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model Inception V3 without final output layer\n",
    "cnnModel = InceptionV3(weights='imagenet', \n",
    "                       include_top=False,        # this removes the final layer\n",
    "                       input_shape=img_shape, \n",
    "                       pooling = 'avg')\n",
    "\n",
    "# freeze all convolutional InceptionV3 layers\n",
    "for layer in cnnModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# make input layers for model definition\n",
    "inputImg = keras.Input(shape=img_shape)    # input layer for CNN\n",
    "embLabels = keras.Input(shape=(300,))          # input layer with the avg label word embedding\n",
    "# image embedding\n",
    "embImage = cnnModel(inputImg)\n",
    "\n",
    "# image and word embeddings concatenation to build a 2348 dimensional layer\n",
    "concat = keras.layers.Concatenate(axis=1)([embImage, embLabels])\n",
    "totalEmbeddingLayer = Dense(300, activation='relu')(concat)\n",
    "\n",
    "# add softmax layer to get probabilities\n",
    "\n",
    "softmax1 = Dense(300,activation = 'softmax', name = 'softmax_encoder')(totalEmbeddingLayer)\n",
    "# multiply softmax probabilities with the image embedding to \n",
    "# get probability weighted vector that gets us the input to the LSTM\n",
    "\n",
    "lstm_hidden_input = keras.layers.Multiply()([totalEmbeddingLayer, softmax1])\n",
    "\n",
    "encoder = keras.Model(inputs=[inputImg, embLabels], outputs=lstm_hidden_input)\n",
    "\n",
    "initial_state_LSTM = encoder([inputImg, embLabels])\n",
    "\n",
    "#Input to the decoder would be the caption sequence starting from <START> character and ending in <END> character\n",
    "decoder_inputs = keras.Input(shape = (de_shape,))\n",
    "\n",
    "# make a trainable embedding layer that uses the GloVe embeddings but still allows training\n",
    "input_caption_emb = Embedding(input_dim=vocab_size, output_dim=embedding_size,\n",
    "                              input_length=maxlend, W_regularizer = None,\n",
    "                              weights = [embeddings], name = 'caption_embeddings', \n",
    "                              trainable = True # making this a trainable embedding \n",
    "                                               # layer that's initialized using GloVe\n",
    "                              )\n",
    "\n",
    "decoder_LSTM = LSTM(hidden_units,return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_outputs, _ , _ = decoder_LSTM(input_caption_emb(decoder_inputs), \n",
    "                                      initial_state = [initial_state_LSTM, initial_state_LSTM])\n",
    "\n",
    "# Apply a dense layer that has vocab_size(40000 ish) outputs which learns probability of each word when softmax is applied.\n",
    "# TimeDistributed is a wrapper for applying the same function over all the time step outputs. \n",
    "# Refer https://keras.io/layers/wrappers/\n",
    "time_distributed = TimeDistributed(Dense(vocab_size, name = 'timedistributed_1'))\n",
    "activation = Activation('softmax')\n",
    "decoder_outputs = activation(time_distributed(decoder_outputs))\n",
    "\n",
    "#Model groups layers into an object with training and inference features.\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/models/Model        \n",
    "model= Model(inputs=[inputImg, embLabels,decoder_inputs], outputs=decoder_outputs)\n",
    "rmsprop = RMSprop(lr=0.1,clipnorm=clip_norm)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=rmsprop)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
